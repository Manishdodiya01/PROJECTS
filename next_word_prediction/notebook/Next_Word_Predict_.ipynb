{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP1Jsof8Tfpi"
   },
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYZOFwM98hhX",
    "outputId": "912a04c9-f015-4026-d606-c3d83c5078c0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM , Dense , Embedding , BatchNormalization , GRU , Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vNg_7k9T07h"
   },
   "source": [
    "# Reading Text Data into Pandas DataFrame with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CLphJ19NEGFr",
    "outputId": "b949cac7-7e75-4751-98f0-68c136e80610",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9633,\n  \"fields\": [\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9574,\n        \"samples\": [\n          \"proficient in his profession but is also discreet and capable of\",\n          \"screen over that dark lantern.\\u201d\",\n          \"as it happened, sir,\\u201d said he. \\u201cWhen Horner had been arrested, it\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5027c21b-778e-4ceb-9673-2bff70163b4b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Gutenberg's The Adventures of Sherlock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This eBook is for the use of anyone anywhere a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almost no restrictions whatsoever.  You may co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>re-use it under the terms of the Project Guten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with this eBook or online at www.gutenberg.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5027c21b-778e-4ceb-9673-2bff70163b4b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5027c21b-778e-4ceb-9673-2bff70163b4b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5027c21b-778e-4ceb-9673-2bff70163b4b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-f1986c9e-21a3-441b-ac1b-c0872479f7e2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1986c9e-21a3-441b-ac1b-c0872479f7e2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-f1986c9e-21a3-441b-ac1b-c0872479f7e2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                data\n",
       "0  Project Gutenberg's The Adventures of Sherlock...\n",
       "1  This eBook is for the use of anyone anywhere a...\n",
       "2  almost no restrictions whatsoever.  You may co...\n",
       "3  re-use it under the terms of the Project Guten...\n",
       "4     with this eBook or online at www.gutenberg.net"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempt to read the file, skipping problematic lines and generating a warning\n",
    "df = pd.read_csv(\"1661-0.txt\", sep='\\t',names=['data'] )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g9duEMLUDxx"
   },
   "source": [
    "# Converting DataFrame to Text String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Us7ELawEMPo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df.to_string(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ny_Gf7KGXgl"
   },
   "source": [
    "# Fitting Tokenizer on Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7EG478hiGswE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQF20dDMU6a3"
   },
   "source": [
    "#After fitting the tokenizer on the text data, you can access the word counts and the word index using `tokenizer.word_counts` and `tokenizer.word_index` attributes respectively.\n",
    "- `tokenizer.word_counts` provides a dictionary containing the counts of each word in the text data.\n",
    "- `tokenizer.word_index` provides a dictionary mapping each word to its corresponding index in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rWrrFMKvHl-T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer.word_counts\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96evyE1HVGFw"
   },
   "source": [
    "# Splitting Text Data into Sentences and Printing Each Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pX17xaAeIItu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for sentence in data.split('\\n'):\n",
    "  #print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZmSf07fVLgX"
   },
   "source": [
    "# Converting Sentences to Sequences using Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KBaP_MVkJ2JU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for sentence in data.split('\\n'):\n",
    "  #print(tokenizer.texts_to_sequences([sentence])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-P35AZ-VkQw"
   },
   "source": [
    "# Generating Input Sequences for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6GU82Uz4NxtV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for sentence in data.split('\\n'):\n",
    "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0] # tokenizer.texts_to_sequences()` method, which converts the sentence into a sequence of integers.\n",
    "\n",
    "  for i in range(1 , len(tokenized_sentence)):\n",
    "    input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZ8S-GKyYf5Q"
   },
   "source": [
    "# Calculate the maximum length of the input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvGXPNksRf3j",
    "outputId": "356faa86-099a-46f4-8453-5fed9b309626",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(len(x) for x in input_sequences)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmo66_Y5Y1Wf"
   },
   "source": [
    "# The code uses the pad_sequences() function from Keras.preprocessing.sequence module to pad the input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cUUed0ITR9Zf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded_input_sequences = pad_sequences(input_sequences , maxlen=max_len , padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1062BthtSgZH",
    "outputId": "b5948337-a173-4c09-d13e-cd73b3a8602c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,  145, 4789],\n",
       "       [   0,    0,    0, ...,  145, 4789,    1],\n",
       "       [   0,    0,    0, ..., 4789,    1, 1021],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    3,  360,   83],\n",
       "       [   0,    0,    0, ...,  360,   83,  358],\n",
       "       [   0,    0,    0, ...,   83,  358, 1673]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gKEkBX6zXlxa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Slice the padded input sequences to create input data (X)\n",
    "X = padded_input_sequences[:, :-1]\n",
    "\n",
    "# Slice the padded input sequences to create target data (Y)\n",
    "Y = padded_input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgIS1BJiZDAV",
    "outputId": "60ec5f91-7b55-4f9d-e71f-f48fa58591df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-SHAPE : (101619, 19)\n",
      "Y-SHAPE : (101619,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X-SHAPE :\",X.shape)\n",
    "print(\"Y-SHAPE :\",Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThXjYEoBaJqU"
   },
   "source": [
    "# Convert target data Y to one-hot encoded format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfMOhXBiahg7",
    "outputId": "ee02e9a7-c01f-44cf-df49-96564c00a4de",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER-ONE_HOT_ENCODED-Y : (101619, 8931)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "Y = to_categorical(Y , num_classes=vocabulary_size)\n",
    "\n",
    "print(\"AFTER-ONE_HOT_ENCODED-Y :\",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_aNVebGbwnO",
    "outputId": "a9abb425-a0f4-450b-b962-ef8572f1b2c6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJCCnDAYkq-2"
   },
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7pXqnPXakv3s"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJ448Y0SqPkh"
   },
   "source": [
    "# Sequential Model Architecture with Embedding, LSTM, and Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaLtAfmNVlXV",
    "outputId": "296c429a-e0be-4ab8-f4b1-355260006d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary-size = 8931\n",
      "Max-Len = 20\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary-size =',vocabulary_size)\n",
    "print('Max-Len =',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QD8ujomXcP54",
    "outputId": "d2fe7263-d511-449d-9ef8-adb688b1ff14",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocabulary_size, output_dim=200, input_length=max_len-1))\n",
    "model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
    "model.add(GRU(200, dropout=0.2, recurrent_dropout=0.2))  # GRU layer with 200 units and dropout\n",
    "model.add(Dense(vocabulary_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if4gp77_qTkM"
   },
   "source": [
    "# Compiling the Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-a1_DO62eeX_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdYLTiRRqXQC"
   },
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxMuCxIZepXO",
    "outputId": "e558aead-25c5-4a52-ef87-a5775393e25d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 19, 200)           1786200   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 19, 200)           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 200)               241200    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8931)              1795131   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3822531 (14.58 MB)\n",
      "Trainable params: 3822531 (14.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuD6bAg0qlST"
   },
   "source": [
    "# Training the Sequential Model with Early Stopping Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "op-cuAJWerVR",
    "outputId": "3226543a-8cb8-45ac-c0c3-78a3fc9321dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1271/1271 [==============================] - 103s 77ms/step - loss: 6.2800 - accuracy: 0.0808 - val_loss: 5.8125 - val_accuracy: 0.1122\n",
      "Epoch 2/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 5.4334 - accuracy: 0.1278 - val_loss: 5.6397 - val_accuracy: 0.1346\n",
      "Epoch 3/50\n",
      "1271/1271 [==============================] - 88s 69ms/step - loss: 4.9931 - accuracy: 0.1541 - val_loss: 5.6137 - val_accuracy: 0.1451\n",
      "Epoch 4/50\n",
      "1271/1271 [==============================] - 82s 65ms/step - loss: 4.6088 - accuracy: 0.1768 - val_loss: 5.6600 - val_accuracy: 0.1501\n",
      "Epoch 5/50\n",
      "1271/1271 [==============================] - 83s 66ms/step - loss: 4.2541 - accuracy: 0.1987 - val_loss: 5.7647 - val_accuracy: 0.1506\n",
      "Epoch 6/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 3.9416 - accuracy: 0.2253 - val_loss: 5.8561 - val_accuracy: 0.1481\n",
      "Epoch 7/50\n",
      "1271/1271 [==============================] - 81s 64ms/step - loss: 3.6599 - accuracy: 0.2566 - val_loss: 5.9761 - val_accuracy: 0.1466\n",
      "Epoch 8/50\n",
      "1271/1271 [==============================] - 82s 64ms/step - loss: 3.4213 - accuracy: 0.2897 - val_loss: 6.0712 - val_accuracy: 0.1451\n",
      "Epoch 9/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 3.2107 - accuracy: 0.3189 - val_loss: 6.1811 - val_accuracy: 0.1429\n",
      "Epoch 10/50\n",
      "1271/1271 [==============================] - 82s 65ms/step - loss: 3.0312 - accuracy: 0.3481 - val_loss: 6.2830 - val_accuracy: 0.1423\n",
      "Epoch 11/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 2.8722 - accuracy: 0.3725 - val_loss: 6.3669 - val_accuracy: 0.1418\n",
      "Epoch 12/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 2.7405 - accuracy: 0.3924 - val_loss: 6.4595 - val_accuracy: 0.1377\n",
      "Epoch 13/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 2.6192 - accuracy: 0.4145 - val_loss: 6.5436 - val_accuracy: 0.1349\n",
      "Epoch 14/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 2.5160 - accuracy: 0.4303 - val_loss: 6.6260 - val_accuracy: 0.1352\n",
      "Epoch 15/50\n",
      "1271/1271 [==============================] - 81s 64ms/step - loss: 2.4204 - accuracy: 0.4469 - val_loss: 6.7081 - val_accuracy: 0.1339\n",
      "Epoch 16/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 2.3413 - accuracy: 0.4608 - val_loss: 6.7777 - val_accuracy: 0.1314\n",
      "Epoch 17/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 2.2684 - accuracy: 0.4727 - val_loss: 6.8590 - val_accuracy: 0.1311\n",
      "Epoch 18/50\n",
      "1271/1271 [==============================] - 82s 65ms/step - loss: 2.1915 - accuracy: 0.4859 - val_loss: 6.9546 - val_accuracy: 0.1320\n",
      "Epoch 19/50\n",
      "1271/1271 [==============================] - 82s 64ms/step - loss: 2.1380 - accuracy: 0.4958 - val_loss: 7.0136 - val_accuracy: 0.1321\n",
      "Epoch 20/50\n",
      "1271/1271 [==============================] - 87s 68ms/step - loss: 2.0811 - accuracy: 0.5081 - val_loss: 7.0764 - val_accuracy: 0.1299\n",
      "Epoch 21/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 2.0351 - accuracy: 0.5146 - val_loss: 7.1522 - val_accuracy: 0.1305\n",
      "Epoch 22/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 1.9873 - accuracy: 0.5251 - val_loss: 7.2262 - val_accuracy: 0.1296\n",
      "Epoch 23/50\n",
      "1271/1271 [==============================] - 81s 64ms/step - loss: 1.9494 - accuracy: 0.5305 - val_loss: 7.2786 - val_accuracy: 0.1250\n",
      "Epoch 24/50\n",
      "1271/1271 [==============================] - 82s 65ms/step - loss: 1.9041 - accuracy: 0.5398 - val_loss: 7.3447 - val_accuracy: 0.1245\n",
      "Epoch 25/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 1.8774 - accuracy: 0.5427 - val_loss: 7.4119 - val_accuracy: 0.1252\n",
      "Epoch 26/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 1.8427 - accuracy: 0.5497 - val_loss: 7.4652 - val_accuracy: 0.1262\n",
      "Epoch 27/50\n",
      "1271/1271 [==============================] - 86s 68ms/step - loss: 1.8103 - accuracy: 0.5554 - val_loss: 7.5240 - val_accuracy: 0.1251\n",
      "Epoch 28/50\n",
      "1271/1271 [==============================] - 86s 68ms/step - loss: 1.7849 - accuracy: 0.5609 - val_loss: 7.5722 - val_accuracy: 0.1247\n",
      "Epoch 29/50\n",
      "1271/1271 [==============================] - 86s 68ms/step - loss: 1.7624 - accuracy: 0.5636 - val_loss: 7.6437 - val_accuracy: 0.1259\n",
      "Epoch 30/50\n",
      "1271/1271 [==============================] - 81s 64ms/step - loss: 1.7379 - accuracy: 0.5698 - val_loss: 7.6913 - val_accuracy: 0.1237\n",
      "Epoch 31/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 1.7063 - accuracy: 0.5735 - val_loss: 7.7505 - val_accuracy: 0.1238\n",
      "Epoch 32/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 1.6825 - accuracy: 0.5795 - val_loss: 7.8016 - val_accuracy: 0.1257\n",
      "Epoch 33/50\n",
      "1271/1271 [==============================] - 82s 64ms/step - loss: 1.6697 - accuracy: 0.5816 - val_loss: 7.8378 - val_accuracy: 0.1243\n",
      "Epoch 34/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 1.6444 - accuracy: 0.5881 - val_loss: 7.9059 - val_accuracy: 0.1210\n",
      "Epoch 35/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 1.6294 - accuracy: 0.5912 - val_loss: 7.9253 - val_accuracy: 0.1221\n",
      "Epoch 36/50\n",
      "1271/1271 [==============================] - 88s 69ms/step - loss: 1.6150 - accuracy: 0.5918 - val_loss: 7.9791 - val_accuracy: 0.1178\n",
      "Epoch 37/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 1.5929 - accuracy: 0.5976 - val_loss: 8.0306 - val_accuracy: 0.1254\n",
      "Epoch 38/50\n",
      "1271/1271 [==============================] - 82s 64ms/step - loss: 1.5800 - accuracy: 0.5980 - val_loss: 8.0708 - val_accuracy: 0.1235\n",
      "Epoch 39/50\n",
      "1271/1271 [==============================] - 87s 69ms/step - loss: 1.5717 - accuracy: 0.5990 - val_loss: 8.1164 - val_accuracy: 0.1220\n",
      "Epoch 40/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 1.5464 - accuracy: 0.6061 - val_loss: 8.1471 - val_accuracy: 0.1207\n",
      "Epoch 41/50\n",
      "1271/1271 [==============================] - 82s 65ms/step - loss: 1.5417 - accuracy: 0.6044 - val_loss: 8.1798 - val_accuracy: 0.1202\n",
      "Epoch 42/50\n",
      "1271/1271 [==============================] - 83s 65ms/step - loss: 1.5229 - accuracy: 0.6108 - val_loss: 8.2258 - val_accuracy: 0.1196\n",
      "Epoch 43/50\n",
      "1271/1271 [==============================] - 81s 64ms/step - loss: 1.5149 - accuracy: 0.6123 - val_loss: 8.2686 - val_accuracy: 0.1189\n",
      "Epoch 44/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 1.5062 - accuracy: 0.6144 - val_loss: 8.3156 - val_accuracy: 0.1215\n",
      "Epoch 45/50\n",
      "1271/1271 [==============================] - 85s 67ms/step - loss: 1.4913 - accuracy: 0.6152 - val_loss: 8.3430 - val_accuracy: 0.1161\n",
      "Epoch 46/50\n",
      "1271/1271 [==============================] - 82s 65ms/step - loss: 1.4794 - accuracy: 0.6171 - val_loss: 8.3802 - val_accuracy: 0.1149\n",
      "Epoch 47/50\n",
      "1271/1271 [==============================] - 83s 66ms/step - loss: 1.4748 - accuracy: 0.6197 - val_loss: 8.4124 - val_accuracy: 0.1166\n",
      "Epoch 48/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 1.4635 - accuracy: 0.6215 - val_loss: 8.4488 - val_accuracy: 0.1210\n",
      "Epoch 49/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 1.4522 - accuracy: 0.6248 - val_loss: 8.4662 - val_accuracy: 0.1161\n",
      "Epoch 50/50\n",
      "1271/1271 [==============================] - 84s 66ms/step - loss: 1.4461 - accuracy: 0.6255 - val_loss: 8.5172 - val_accuracy: 0.1167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=64, validation_data=(X_test, Y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZRG0RJPnCZL",
    "outputId": "6ce08bd0-3ffa-43f6-d8c5-496f2674885f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"next_word_prediction_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZdYwV0mmv2O",
    "outputId": "11002d26-269d-48d1-eb6f-a83f44743589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tokenizer, \"tokenizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ubMIyFkelQMD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12Zb3NtUu6Yk"
   },
   "source": [
    "# Generate next words iteratively based on the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWvLRjwLpfvK",
    "outputId": "347e7d55-ae25-447f-c4dc-77deae579678",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 316ms/step\n",
      "I tell you that I would give one of the provinces of\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "I tell you that I would give one of the provinces of my\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "I tell you that I would give one of the provinces of my kingdom\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "I tell you that I would give one of the provinces of my kingdom to\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "I tell you that I would give one of the provinces of my kingdom to you\n"
     ]
    }
   ],
   "source": [
    "def generate_next_word(text , model , tokenizer , maxlen=19 , padding='pre' , wait_time=0.2 , num_predictions=5):\n",
    "\n",
    "  for i in range(num_predictions):\n",
    "\n",
    "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "    padded_text = pad_sequences([token_text] , maxlen=maxlen , padding=padding)\n",
    "\n",
    "    predict = np.argmax(model.predict(padded_text))\n",
    "\n",
    "    for word , index in tokenizer.word_index.items():\n",
    "      if index == predict:\n",
    "        text = text + \" \" + word\n",
    "        print(text)\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "input_text = \"I tell you that I would give one of the provinces\"\n",
    "generate_next_word(input_text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mxjOPTJangm-"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the function\n",
    "with open(\"generate_next_word.pkl\", \"wb\") as f:\n",
    "    pickle.dump(generate_next_word, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgCvufOkniOA",
    "outputId": "c24f5762-bece-453f-fd5c-b1e079d7881e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts/tokenizer.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/tokenizer.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load modela\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'artifacts/tokenizer.joblib'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "with open(\"\", \"rb\") as f:\n",
    "    tokenizer = joblib.load(f)\n",
    "\n",
    "# Load modela\n",
    "model = load_model(\"next_word_prediction_model.h5\")\n",
    "\n",
    "# Load generate_next_word function\n",
    "with open(\"generate_next_word.pkl\", \"rb\") as f:\n",
    "    generate_next_word = joblib.load(f)\n",
    "\n",
    "def predict_next_word(input_text):\n",
    "    token_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    padded_text = pad_sequences([token_text], maxlen=19, padding='pre')\n",
    "    predicted_probabilities = model.predict(padded_text)[0]\n",
    "    next_word_index = np.argmax(predicted_probabilities)\n",
    "    next_word = tokenizer.index_word[next_word_index]\n",
    "    return next_word\n",
    "\n",
    "def generate_next_word_text(input_text, num_predictions=5):\n",
    "    for i in range(num_predictions):\n",
    "        input_text = predict_next_word(input_text)\n",
    "        print(input_text)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "# Example usage\n",
    "input_text = \"I tell you that I would give one of the provinces\"\n",
    "generate_next_word_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "fZX3SRvS4uC1",
    "outputId": "04f1a1a4-8fab-4d56-a8de-8fa1d6e47c95"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n2Xpnb5S7mYC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
