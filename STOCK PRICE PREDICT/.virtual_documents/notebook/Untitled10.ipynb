import tensorflow as tf
import keras


file_path = "https://www.kaggle.com/datasets/parve05/customer-review-dataset"

data_dir = keras.utils.get_file("customer_data" , origin=file_path , untar=True)


len(data_dir)


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


pd.read_csv('EW-MAX.csv')


df = pd.read_csv('EW-MAX.csv')


df.info()


df.isnull().sum()


df.duplicated().sum()


a = df[['Open' , 'High' , 'Low']]



sorted_df = df.sort_values('Volume' , ascending=True).head(10)
sorted_df


sorted_df = df.sort_values('High' , ascending=True).head(10)
sorted_df


df.describe().transpose()


df.query("Volume > 1500000").sort_values("Volume" , ascending=False)


sns.displot(df['High'] )


sns.histplot(df.High)


x = df.drop(['Close','Date','Adj_Close'] , axis=1)
y = df['Close']


x.shape


y.shape


X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=42)


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score
import numpy as np
from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from xgboost import XGBRegressor


def evaluate_model(y_test,y_pred):

  mse = mean_squared_error(y_test,y_pred)
  mae = mean_absolute_error(y_test,y_pred)
  rmse = np.sqrt(mean_squared_error(y_test,y_pred))
  r2 = r2_score(y_test,y_pred)

  return mae , rmse , r2


models={
    'LinearRegression':LinearRegression(),
    'Lasso':Lasso(),
    'Ridge':Ridge(),
    'Elasticnet':ElasticNet(),
    'DecisionTree' : DecisionTreeRegressor(),
    "XGBRegressor" : XGBRegressor()
}


len(models)


models.items()


for model_name , model in models.items():
  model.fit(X_train,y_train)

  y_pred = model.predict(X_test)

  mae , rmse , r2 = evaluate_model(y_test,y_pred)

  print(model_name)
  print('MODEL TRAINING PERFORMANCE')
  print("RMSE:",rmse * 100)
  print('MAE:',mae * 100)
  print('R2:',r2*100)

  print('*'*35)
  print('ðŸŽ†'*15)
  print('*'*35)
  print('\n')




model_ridge = Ridge()
model_ridge.fit(X_train,y_train)
y_pred = model_ridge.predict(X_test)


MSE = mean_squared_error(y_test,y_pred) * 100
R2_SCORE = r2_score(y_test,y_pred) * 100
print('MSE = ',MSE)
print('R2-SCORE = ',R2_SCORE)


import joblib


joblib.dump(model_ridge , "model.joblib")


joblib.dump(scaler , "scaler.joblib")



